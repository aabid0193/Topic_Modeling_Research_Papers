{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/benhamner/nips-papers/blob/master/src/download_papers.py\n",
    "def text_from_pdf(pdf_path, temp_path):\n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "    subprocess.call([\"pdftotext\", pdf_path, temp_path])\n",
    "    f = open(temp_path, encoding=\"utf8\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    os.remove(temp_path)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url  = \"http://papers.nips.cc\"\n",
    "\n",
    "index_urls = {1987: \"https://papers.nips.cc/book/neural-information-processing-systems-1987\"}\n",
    "for i in range(1, 30):\n",
    "    year = i+1987\n",
    "    index_urls[year] = \"http://papers.nips.cc/book/advances-in-neural-information-processing-systems-%d-%d\" % (i, year)\n",
    "\n",
    "nips_authors = set()\n",
    "papers = list()\n",
    "paper_authors = list()\n",
    "\n",
    "for year in sorted(index_urls.keys()):\n",
    "    index_url = index_urls[year]\n",
    "    index_html_path = os.path.join(\"working\", \"html\", str(year)+\".html\")\n",
    "\n",
    "    if not os.path.exists(index_html_path):\n",
    "        r = requests.get(index_url)\n",
    "        if not os.path.exists(os.path.dirname(index_html_path)):\n",
    "            os.makedirs(os.path.dirname(index_html_path))\n",
    "        with open(index_html_path, \"wb\") as index_html_file:\n",
    "            index_html_file.write(r.content)\n",
    "    with open(index_html_path, \"rb\") as f:\n",
    "       html_content = f.read()\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    paper_links = [link for link in soup.find_all('a') if link[\"href\"][:7]==\"/paper/\"]\n",
    "    print(\"%d Papers Found\" % len(paper_links))\n",
    "\n",
    "\n",
    "    temp_path = os.path.join(\"working\", \"temp.txt\")\n",
    "\n",
    "    for link in paper_links:\n",
    "        paper_title = link.contents[0]\n",
    "        info_link = base_url + link[\"href\"]\n",
    "        pdf_link = info_link + \".pdf\"\n",
    "        pdf_name = link[\"href\"][7:] + \".pdf\"\n",
    "        pdf_path = os.path.join(\"working\", \"pdfs\", str(year), pdf_name)\n",
    "        paper_id = re.findall(r\"^(\\d+)-\", pdf_name)[0]\n",
    "        print(year, \" \", paper_id) #paper_title.encode('ascii', 'namereplace'))\n",
    "        if not os.path.exists(pdf_path):\n",
    "            pdf = requests.get(pdf_link)\n",
    "            if not os.path.exists(os.path.dirname(pdf_path)):\n",
    "                os.makedirs(os.path.dirname(pdf_path))\n",
    "            pdf_file = open(pdf_path, \"wb\")\n",
    "            pdf_file.write(pdf.content)\n",
    "            pdf_file.close()\n",
    "\n",
    "        paper_info_html_path = os.path.join(\"working\", \"html\", str(year), str(paper_id)+\".html\")\n",
    "        if not os.path.exists(paper_info_html_path):\n",
    "            r = requests.get(info_link)\n",
    "            if not os.path.exists(os.path.dirname(paper_info_html_path)):\n",
    "                os.makedirs(os.path.dirname(paper_info_html_path))\n",
    "            with open(paper_info_html_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        with open(paper_info_html_path, \"rb\") as f:\n",
    "           html_content = f.read()\n",
    "        paper_soup = BeautifulSoup(html_content, \"lxml\")\n",
    "        try: \n",
    "            abstract = paper_soup.find('p', attrs={\"class\": \"abstract\"}).contents[0]\n",
    "        except:\n",
    "            print(\"Abstract not found %s\" % paper_title.encode(\"ascii\", \"replace\"))\n",
    "            abstract = \"\"\n",
    "        authors = [(re.findall(r\"-(\\d+)$\", author.contents[0][\"href\"])[0],\n",
    "                    author.contents[0].contents[0])\n",
    "                   for author in paper_soup.find_all('li', attrs={\"class\": \"author\"})]\n",
    "        for author in authors:\n",
    "            nips_authors.add(author)\n",
    "            paper_authors.append([len(paper_authors)+1, paper_id, author[0]])\n",
    "        event_types = [h.contents[0][23:] for h in paper_soup.find_all('h3') if h.contents[0][:22]==\"Conference Event Type:\"]\n",
    "        if len(event_types) != 1:\n",
    "            #print(event_types)\n",
    "            #print([h.contents for h in paper_soup.find_all('h3')].__str__().encode(\"ascii\", \"replace\"))\n",
    "            #raise Exception(\"Bad Event Data\")\n",
    "            event_type = \"\"\n",
    "        else:\n",
    "            event_type = event_types[0]\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            if f.read(15)==b\"<!DOCTYPE html>\":\n",
    "                print(\"PDF MISSING\")\n",
    "                continue\n",
    "        paper_text = text_from_pdf(pdf_path, temp_path)\n",
    "        papers.append([paper_id, year, paper_title, event_type, pdf_name, abstract, paper_text])\n",
    "\n",
    "pd.DataFrame(list(nips_authors), columns=[\"id\",\"name\"]).sort_values(by=\"id\").to_csv(\"output/authors.csv\", index=False)\n",
    "pd.DataFrame(papers, columns=[\"id\", \"year\", \"title\", \"event_type\", \"pdf_name\", \"abstract\", \"paper_text\"]).sort_values(by=\"id\").to_csv(\"output/papers.csv\", index=False)\n",
    "pd.DataFrame(paper_authors, columns=[\"id\", \"paper_id\", \"author_id\"]).sort_values(by=\"id\").to_csv(\"output/paper_authors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/anaconda3/lib/python3.6/site-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "def text_from_pdf(pdf_path, temp_path):\n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "    subprocess.call([\"pdftotext\", pdf_path, temp_path])\n",
    "    f = open(temp_path, encoding=\"utf8\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    os.remove(temp_path)\n",
    "    return text\n",
    "\n",
    "papers = list()\n",
    "temp_path = os.path.join(\"output\", \"temp.txt\")\n",
    "\n",
    "for year in range(1987,2017):\n",
    "\n",
    "    pdf_names = [p for p in os.listdir(os.path.join(\"output\", \"pdfs\", str(year))) if p.endswith(\".pdf\")]\n",
    "\n",
    "    for pdf_name in pdf_names:\n",
    "        pdf_path = os.path.join(\"output\", \"pdfs\", str(year), pdf_name)\n",
    "        print(year, pdf_path, len(papers))\n",
    "        paper_id = re.findall(r\"^(\\d+)-\", pdf_name)[0]\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            if f.read(15)==b\"<!DOCTYPE html>\":\n",
    "                print(\"PDF MISSING\")\n",
    "                continue\n",
    "        paper_text = text_from_pdf(pdf_path, temp_path)\n",
    "        papers.append([paper_id, year, pdf_name, paper_text])\n",
    "\n",
    "pd.DataFrame(papers, columns=[\"Id\", \"Year\", \"PdfName\", \"PaperText\"]).to_csv(\"output/Papers.csv\", index=False)\n",
    "\n",
    "print(\"COMPLETED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
